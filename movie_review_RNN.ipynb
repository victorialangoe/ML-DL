{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "import os\n",
    "import numpy as np \n",
    "\n",
    "VOCAB_SIZE = 88584\n",
    "\n",
    "MAX_LEN = 250\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "(train_data, train_labels),(test_data, test_labels) = imdb.load_data(num_words= VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IMDB movie review from keras contains 25 000 reviews from IMDB where each on is already preprocesses and has a label as either positive or negative. Each review is encoded by integers that represents how common a word is in the entire dataset. For example, if a word is encoded by the integer 3, it means that it is the 3rd most common word in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "189\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data[0]))\n",
    "print(len(train_data[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our reviews have different lenghts which is an issue. We cannot pass different length data into our neural network.\n",
    "- If the review is greater than 250 words then we trim off extra words\n",
    "- If the review is less than 250 we add necessary amount of 0's to make it equal to 250.\n",
    "We pad the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "train_data = sequence.pad_sequences(train_data, MAX_LEN)\n",
    "test_data = sequence.pad_sequences(test_data, MAX_LEN)\n",
    "print(len(train_data[0]))\n",
    "print(len(train_data[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model\n",
    "We'll use a word embedding layer as the first layer in our model and add a LSTM layer afterwards that feeds into a dense node to get our predicted sentiment\n",
    "\n",
    "32 stands for the output dimension of the vectors generated by the embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 32)          2834688   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2843041 (10.85 MB)\n",
      "Trainable params: 2843041 (10.85 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 20s 31ms/step - loss: 0.4173 - acc: 0.8099 - val_loss: 0.2858 - val_acc: 0.8858\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 19s 31ms/step - loss: 0.2359 - acc: 0.9113 - val_loss: 0.3051 - val_acc: 0.8908\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 19s 30ms/step - loss: 0.1830 - acc: 0.9320 - val_loss: 0.2838 - val_acc: 0.8932\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 19s 30ms/step - loss: 0.1517 - acc: 0.9467 - val_loss: 0.2780 - val_acc: 0.8886\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 19s 30ms/step - loss: 0.1290 - acc: 0.9556 - val_loss: 0.2955 - val_acc: 0.8860\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 19s 31ms/step - loss: 0.1095 - acc: 0.9620 - val_loss: 0.2936 - val_acc: 0.8812\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 19s 31ms/step - loss: 0.0979 - acc: 0.9677 - val_loss: 0.3543 - val_acc: 0.8866\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 20s 31ms/step - loss: 0.0894 - acc: 0.9704 - val_loss: 0.3392 - val_acc: 0.8874\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 20s 32ms/step - loss: 0.0780 - acc: 0.9748 - val_loss: 0.3472 - val_acc: 0.8858\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 19s 31ms/step - loss: 0.0688 - acc: 0.9776 - val_loss: 0.4203 - val_acc: 0.8822\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "history = model.fit(train_data, train_labels, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 6s 8ms/step - loss: 0.4974 - acc: 0.8568\n",
      "[0.4974336624145508, 0.8568000197410583]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data has been preprocessed when we gave it to our model this means we need to process anything we want to make a prediction on in the exact same way. Same lookup table, encode it precisely the same. If we don't, the model is going to think it is looking at different words and will not make an accurate prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   1  17  13  35 477]\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "\n",
    "def encode_text(text):\n",
    "    tokens = tf.keras.preprocessing.text.text_to_word_sequence(text) # tokens = individual words\n",
    "    tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
    "    \n",
    "    return sequence.pad_sequences([tokens],MAX_LEN)[0]\n",
    "\n",
    "text = \"the movie was so amazing\"\n",
    "encoded = encode_text(text=text)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the movie was so amazing\n"
     ]
    }
   ],
   "source": [
    "# Decoding\n",
    "\n",
    "reverse_word_index = {value: key for (key,value) in word_index.items()}\n",
    "\n",
    "def decode_integers(integers):\n",
    "    PAD = 0\n",
    "    text = \"\"\n",
    "    for num in integers:\n",
    "        if num != PAD:\n",
    "            text += reverse_word_index[num] + \" \"\n",
    "    \n",
    "    return text[:-1]\n",
    "\n",
    "print(decode_integers(encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0.84790605]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "[0.79853654]\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "\n",
    "def predict(text):\n",
    "    encoded_text = encode_text(text)\n",
    "    pred = np.zeros((1,250))\n",
    "    pred[0] = encoded_text\n",
    "    result = model.predict(pred)\n",
    "    print(result[0])\n",
    "\n",
    "positive_review = \"Wow the movie was so amazing, I loved it!\"\n",
    "predict(positive_review)\n",
    "\n",
    "negative_review = \"The movie was terrible, I will never watch this again!\" # very bad model, gives too high values lmao.\n",
    "predict(negative_review)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
